{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"convolutional_network_raw_DA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPr2algzqMABryPLtt/XOOK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OBKyt1b40TRA"},"source":["#  Bài tâp về mạng tích chập\n","\n","Trong bài này, chúng ta sẽ xây dựng một mạng tích chập sử dụng Torch và thử train&Test tập MNIST nhé. \n"]},{"cell_type":"markdown","metadata":{"id":"xRMw1k_n0YY5"},"source":["## Tổng quan một mạng CNN cơ bản\n","\n","![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n","\n","## MNIST dataset\n","\n","Trong bài tập này, chúng ta sẽ sử dựng tập MNIST rất nổi tiếng vể  các chữ số viết tay từ 0->9. Tập dataset này bao gồm 60000 ảnh cho training và 10000 ảnh cho testing. Các bức ảnh này đều đã được căn giữa và chỉnh với kích thước cố định là 28x28.\n","\n","Trong phần tiền xử lý, chúng ta sẽ cần chuẩn hóa các giá trị pixel của mỗi ảnh về khoảng [0,1], kiểu dữ liệu sẽ là float32\n","\n","<!-- ![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png) -->\n","\n","Chi tiết tại: http://yann.lecun.com/exdb/mnist/"]},{"cell_type":"code","metadata":{"id":"_bmBxOZW0UGC"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PtTud_GsLWP_"},"source":["# Some configs"]},{"cell_type":"code","metadata":{"id":"3z4BK0Vr0bGV"},"source":["# Số classes trong tập MNIST\n","num_classes = 10\n","\n","# Số epoch \n","epochs = 3\n","\n","# Các tham số cần thiết cho quá trình traning.\n","learning_rate = 0.001\n","batch_size = 128\n","display_step = 100\n","\n","# Tham số mạng CNN \n","out_channel_1  = 32 # số channel của đầu ra conv thứ 1\n","out_channel_2 = 64 # số channel của đầu ra conv thứ 2\n","\n","# Path lưu best model \n","checkpoint = 'model.pth' # có thể để dạng *.pth"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2vYvX5WLaX2"},"source":["# Dataloader"]},{"cell_type":"code","metadata":{"id":"f_F7wyna9NR7"},"source":["# Transform image \n","transform=transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,)) \n","    ])\n","\n","# load dataset từ torchvision.datasets\n","train_dataset = datasets.MNIST('../data', train=True, download=True,transform=transform)\n","test_dataset = datasets.MNIST('../data', train=False,transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5UxaA9xLczc"},"source":["# Model\n","\n","- Input shape sẽ là: [-1, 28, 28, 1]. Ở đây -1 sẽ thể hiện batchsize, một batch thì gồm nhiều ảnh 28x28x1 (grayscale, số channel là 1 !)\n","- Chúng ta sẽ định nghĩa một model đơn giản gồm 2 lớp Conv đều có filter size là 3x3 và stride hãy set là 1. \n","- Ngoài ra sẽ có một lớp maxpool, set filter size 2x2\n","- Flow như sau: conv2d_1 -> relu -> conv2d_2 -> relu -> maxpool2d -> dropout -> flatten -> linear1 -> relu -> dropout -> linear2\n"]},{"cell_type":"code","metadata":{"id":"2jfcloyb0dQ9"},"source":["# Định nghĩa model \n","\n","model = nn.Sequential (\n","    nn.Conv2d(1, out_channel_1, 3, 1),\n","    nn.ReLU(),\n","    nn.Conv2d(out_channel_1, out_channel_2, 3, 1),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2),\n","    nn.Dropout(0.3),\n","    nn.Flatten(),\n","    nn.Linear(9216, 64),\n","    nn.ReLU(),\n","    nn.Dropout(0.4),\n","    nn.Linear(64, num_classes)       \n",")\n","\n","# load lại pretrained model (nếu có)\n","try:\n","  model.load_state_dict(torch.load(checkpoint))\n","except:\n","  print(\"!!! Hãy train để có checkpoint file\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20fGKBm6BMRB"},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","best_val_loss = 999\n","\n","for epoch in range(1,epochs):\n","    # Quá trình training \n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output,target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % display_step == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","    # Quá trình testing \n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    # set no grad cho quá trình testing\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output = model(data)\n","            output = F.log_softmax(output,dim=1) # log softmax using F, chu y dim\n","            test_loss += criterion(output,target) \n","            pred = output.argmax(dim = 1,keepdim = True) # argmax để lấy predicted label, chú ý keepdim = True\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    test_loss /= len(test_loader.dataset) \n","    if test_loss < best_val_loss:\n","      best_val_loss = test_loss\n","      torch.save(model.state_dict(), checkpoint)  # Lưu lại model\n","      print(\"***********    TEST_ACC = {}%    ***********\".format(correct))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_NAtF8XBN_l6"},"source":["# Visualize Image"]},{"cell_type":"code","metadata":{"id":"rzU5GUQqGBH5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630211067341,"user_tz":-420,"elapsed":321,"user":{"displayName":"Max Ph","photoUrl":"","userId":"05319390549713197190"}},"outputId":"08eb9ef3-8064-4862-a9ad-8700fb9b32b1"},"source":["# load lại model đã train\n","model.load_state_dict(torch.load(checkpoint))\n","# set eval phase \n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (3): ReLU()\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Dropout(p=0.3, inplace=False)\n","  (6): Flatten(start_dim=1, end_dim=-1)\n","  (7): Linear(in_features=9216, out_features=64, bias=True)\n","  (8): ReLU()\n","  (9): Dropout(p=0.4, inplace=False)\n","  (10): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"RD8Z-ZX_Mlsp"},"source":["item = iter(test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kC33zgmM5ZI"},"source":["data,target = item.next() # lấy một batch ra"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t1-GZt14N-ym"},"source":["test_idx = random.choice(range(len(data))) # lấy index của một phần tử của một batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkahsgWAOo6i"},"source":["data = data[test_idx]\n","target = target[test_idx]\n","assert data.shape == (1,28,28)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCHOlzBvMznD"},"source":["# thử predict \n","\n","def plot(data,model):\n","  data = torch.unsqueeze(data,dim=0) # unsqueeze data\n","  output = model(data)\n","  output = F.log_softmax(output,dim=1) # log softmax, chú ý dim\n","  pred = output.argmax(dim=1,keepdim=True) # argmax, chú ý keepdim \n","  print(\"Predict Number : \", pred[0][0].numpy()) \n","  plt.imshow(data[0][0],cmap='gray')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"Ci0XeQngPdtB","executionInfo":{"status":"ok","timestamp":1630211150641,"user_tz":-420,"elapsed":429,"user":{"displayName":"Max Ph","photoUrl":"","userId":"05319390549713197190"}},"outputId":"09b21f4e-562f-45ae-f214-1fd3aac70df6"},"source":["plot(data,model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predict Number :  4\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"rqF_zKNkQD0F"},"source":[""],"execution_count":null,"outputs":[]}]}