{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:root] *","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"RNN_API.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"u_6VlaH127cn"},"source":["# Recurrent Neural Network Example\n","\n","Xây dựng mạng RNN với PyTorch"]},{"cell_type":"markdown","metadata":{"id":"pDe_29jg27cq"},"source":["## Tổng quan về RNN\n","\n","<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" alt=\"nn\" style=\"width: 600px;\"/>\n","\n","Tài liệu tham khảo:\n","- [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf), Sepp Hochreiter & Jurgen Schmidhuber, Neural Computation 9(8): 1735-1780, 1997.\n","\n","## Tổng quan về bộ dữ liệu MNIST\n","\n","Ví dụ này sử dụng bộ dữ liệu về chữ số viết tay MNIST. Bộ dữ liệu chữa 60k mẫu cho huấn luyện và 10k mẫu cho kiểm thử.\n","\n","![MNIST Dataset](https://i1.wp.com/varianceexplained.org/images/mnist.png?w=456)\n","\n","\n","Để phân loại hình ảnh sử dụng RNN, chúng ta sẽ coi mỗi hàng là 1 chuỗi pixels. Bởi vì kích thước ảnh là 28*28px, ta sẽ sử lý 28 chuỗi của 28 timesteps cho tất cả các sample."]},{"cell_type":"code","metadata":{"id":"gsr5_MTC27cq"},"source":["from __future__ import absolute_import, division, print_function\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXFK6Vlq27cr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630206055391,"user_tz":-420,"elapsed":3294,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}},"outputId":"688afe32-92d5-4886-d0d9-0ad8b3bfb1e3"},"source":["# Chuẩn bị dữ liệu\n","from tensorflow.keras.datasets import mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","# Chuyển đổi sang định dạng float32.\n","x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n","x_train, x_test = x_train.reshape([-1, 28, 28]), x_test.reshape([-1, 28, 28])\n","# Chuẩn hóa ảnh từ from [0, 255] to [0, 1].\n","x_train, x_test = x_train / 255., x_test / 255.\n","x_train, x_test, y_train, y_test = torch.from_numpy(x_train), torch.from_numpy(x_test), torch.from_numpy(y_train).type(torch.LongTensor), torch.from_numpy(y_test).type(torch.LongTensor)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7HLM6P8q6YOh"},"source":["# x_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1PAqVHP27cs"},"source":["trainloader = []\n","for (i,j) in zip(x_train, y_train):\n","    trainloader.append([i,j])\n","trainloader = torch.utils.data.DataLoader(trainloader, shuffle=True, batch_size=16)\n","\n","testloader = []\n","for (i,j) in zip(x_test, y_test):\n","    testloader.append([i,j])\n","testloader = torch.utils.data.DataLoader(testloader, shuffle=True, batch_size=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7f3TRJM427cs"},"source":["# Create RNN Model\n","class RNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n","        super(RNNModel, self).__init__()\n","        \n","        # Number of hidden dimensions\n","        self.hidden_dim = None\n","        \n","        # Number of hidden layers\n","        self.layer_dim = None\n","        \n","        # RNN\n","        self.rnn = nn.RNN(None, None, None, batch_first=True, nonlinearity='relu', bidirectional=False)\n","        \n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, None)\n","    \n","    def forward(self, x):\n","        \n","        # Initialize hidden state with zeros\n","        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n","            \n","        # One time step\n","        out, hn = self.rnn(x, h0)\n","        out = self.fc(out[:, -1, :]) \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0JPoOx2HS4Y"},"source":["# Create RNN\n","input_dim = 28    # input dimension\n","hidden_dim = 100  # hidden layer dimension\n","layer_dim = 1     # number of hidden layers\n","output_dim = 10   # output dimension\n","\n","model = BiRNNModel(None, None, None, None)\n","\n","# Cross Entropy Loss \n","import torch.optim as optim\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTjVi0_PHYj2","executionInfo":{"status":"ok","timestamp":1630063463738,"user_tz":-420,"elapsed":30258,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}},"outputId":"8aa5c6fc-a5b9-4c0d-c24a-bab7bca15170"},"source":["for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(None, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = None\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(None)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 1000 == 999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1,  2000] loss: 2.237\n","[2,  2000] loss: 0.619\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iviMeLju27cv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630061472756,"user_tz":-420,"elapsed":730,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}},"outputId":"63f4101f-9b50-4c68-f774-a4bf72014a90"},"source":["correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        # calculate outputs by running images through the network\n","        outputs = model(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 87 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tJi1Po5xPvtl"},"source":[""],"execution_count":null,"outputs":[]}]}